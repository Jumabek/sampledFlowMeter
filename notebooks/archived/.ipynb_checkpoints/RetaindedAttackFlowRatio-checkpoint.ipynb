{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from os.path import join\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pkt_count(dirs,ending):\n",
    "    counts = []\n",
    "    for d in dirs:\n",
    "        num_sampled_pkts = 0\n",
    "        for f in glob.glob(join(d,ending)):\n",
    "            num_sampled_pkts += int(open(f).readline())\n",
    "        counts.append(num_sampled_pkts)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immediate_subdirs(a_dir, only=''):\n",
    "    if only=='':\n",
    "        return [os.path.join(a_dir, name) for name in os.listdir(a_dir) \n",
    "                if os.path.isdir(os.path.join(a_dir, name)) and name.endswith('_l')]\n",
    "    else:\n",
    "        return [os.path.join(a_dir, name) for name in os.listdir(a_dir)\n",
    "                if os.path.isdir(os.path.join(a_dir, name)) and name.endswith('_l') and (only in name or 'whole' in name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_dists(dirs):\n",
    "    results = []\n",
    "    for d in dirs:\n",
    "        df = pd.read_csv(join(d,'label_dist.csv'),header=None,names=['Label','Count'])\n",
    "        results.append(df)\n",
    "            \n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_dir_names(dirs,ending):\n",
    "    pkt_counts = np.array(get_pkt_count(dirs,ending))\n",
    "    flow_dists = get_flow_dists(dirs)\n",
    "    dir_names = np.array([os.path.basename(dir)[:-2] for dir in dirs])\n",
    "        \n",
    "    sorted_index = np.argsort(dir_names)\n",
    "    pkt_counts = pkt_counts[sorted_index]\n",
    "    flow_dists = [flow_dists[i] for i in sorted_index]\n",
    "    dir_names = dir_names[sorted_index]\n",
    "    \n",
    "    return flow_dists,pkt_counts,dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def autolabel(rects, xpos='center'):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "    *xpos* indicates which side to place the text w.r.t. the center of\n",
    "    the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "    \"\"\"\n",
    "\n",
    "    ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "    offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "    max_height = 0\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "            \n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{0:.2f}%'.format(100*height/max_height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(offset[xpos]*3, 1),  # use 3 points offset\n",
    "                    textcoords=\"offset points\",  # in both directions\n",
    "                    ha=ha[xpos], va='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_comparison(dir_names,counts,ax,dataset_name,y_label):\n",
    "    ind = np.arange(len(dir_names))*20\n",
    "    width=15\n",
    "    N = len(dirs)\n",
    "    colors = []\n",
    "    labels = []\n",
    "    for dir_name in dir_names:\n",
    "        if 'sk_sr' in dir_name:\n",
    "            color='orange'\n",
    "            label = 'sketchflow'\n",
    "        elif 'sgs_e' in dir_name:\n",
    "            color = 'green'\n",
    "            label = 'sgs'\n",
    "        elif 'sf_sr' in dir_name:\n",
    "            color = 'blue'\n",
    "            label = 'sFlow'\n",
    "        elif 'ffs_(' in dir_name:\n",
    "            color = 'red'\n",
    "            label = 'Fast Filtered Sampling'\n",
    "        elif 'sel' in dir_name:\n",
    "            color = 'purple'\n",
    "            label = 'selective flow samp.'\n",
    "        elif 'whole' in dir_name or 'cicflow' in dir_name:\n",
    "            color = 'gray'\n",
    "            label = 'whole data'\n",
    "        else:\n",
    "            print('Investigate plot_comparison',dir_name)\n",
    "            \n",
    "        colors.append(color)\n",
    "        labels.append(label)\n",
    "        \n",
    "    rects = ax.bar(ind,counts,label=dataset_name,width=width,color=colors)\n",
    "\n",
    "    #Add some text for labels, title and custom x-axis tick labels, etc.    \n",
    "    #ax.set_title('Finding Equivalent Sampling Rate for comparision')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(dir_names,rotation=45)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    #ax.margins(0.15)\n",
    "    autolabel(rects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sampler_names(dir_names):\n",
    "    colors = []\n",
    "    sampler_names = []\n",
    "    for dir_name in dir_names:\n",
    "        if 'sk_sr' in dir_name:\n",
    "            color='orange'\n",
    "            label = 'SketchFlow Sampling'\n",
    "        elif 'sgs_e' in dir_name:\n",
    "            color = 'green'\n",
    "            label = 'Sketch Guided Sampling'\n",
    "        elif 'sf_sr' in dir_name:\n",
    "            color = 'blue'\n",
    "            label = 'Random Packet Sampling'\n",
    "        elif 'ffs_(' in dir_name:\n",
    "            color = 'red'\n",
    "            label = 'Fast Filtered Sampling'\n",
    "        elif 'sel' in dir_name:\n",
    "            color = 'purple'\n",
    "            label = 'Selective Flow Sampling'\n",
    "        elif 'whole' in dir_name or 'cicflow' in dir_name:\n",
    "            color = 'gray'\n",
    "            label = 'Without Sampling'\n",
    "        else:\n",
    "            print('Investigate plot_comparison',dir_name)\n",
    "            \n",
    "        colors.append(color)\n",
    "        sampler_names.append(label)\n",
    "    return sampler_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = '/home/juma/data/net_intrusion/CIC-IDS-2018/CSVs'\n",
    "label = 'CIC-IDS-2018'\n",
    "ending = '*.spc'\n",
    "\n",
    "dirs = get_immediate_subdirs(root)\n",
    "flow_dists,pkt_counts,dir_names = get_count_dir_names(dirs,ending)\n",
    "\n",
    "whole_index = np.where(dir_names=='whole')[0][0]\n",
    "total_pkts = pkt_counts[whole_index] \n",
    "sampling_rates = [100*10**round(np.log10(pkt_count/total_pkts)) for pkt_count in pkt_counts]\n",
    "sampler_names = extract_sampler_names(dir_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = flow_dists[whole_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack_labels = whole_df['Label'].values\n",
    "#for label in attack_labels:\n",
    "#    num_flows = whole_df[whole_df['Label']==label]['Count'].values[0]\n",
    "#    print(\"{0:30} - > {1}\".format(label,num_flows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SR of 10 --------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/juma/data/net_intrusion/CIC-IDS-2018/CSVs/retained_attacks/10.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-03688abc25c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:30}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_flows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'retained_attacks'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/juma/data/net_intrusion/CIC-IDS-2018/CSVs/retained_attacks/10.csv'"
     ]
    }
   ],
   "source": [
    "attack_labels = whole_df['Label'].values\n",
    "header = np.concatenate((['Sampling technique'],attack_labels))\n",
    "for sr in [10,1,.1]:\n",
    "    print(\"-----------------SR of {} --------------------\".format(sr))\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    flow_counts = defaultdict(list)\n",
    "    flow_counts['Sampling technique'].append('No sampling')\n",
    "    for i,row in whole_df.iterrows():\n",
    "        flow_counts[row[0]].append('100')    \n",
    "    \n",
    "    for i,sampling_rate in enumerate(sampling_rates):\n",
    "        if sampling_rate==sr:\n",
    "            # below here would form a single table for Sampling_method x Attacks for specific SR\n",
    "            sampler_name = sampler_names[i]\n",
    "            flow_counts['Sampling technique'].append(sampler_name)\n",
    "            flow_dist_df = flow_dists[i]\n",
    "            print('******************{0:20}*********************'.format(sampler_name))\n",
    "            \n",
    "            for label in attack_labels:\n",
    "                #make list dictionary for each attack type on sampler names\n",
    "                if len(flow_dist_df[flow_dist_df['Label']==label]['Count'])>0:\n",
    "                    num_flows = flow_dist_df[flow_dist_df['Label']==label]['Count'].values[0]\n",
    "                else:\n",
    "                    num_flows = 0\n",
    "                original_num_flows = whole_df[whole_df['Label']==label]['Count'].values[0]\n",
    "                \n",
    "                flow_counts[label].append('{:.2f}'.format(100*num_flows/original_num_flows))\n",
    "                print('{:30}'.format(label),num_flows)\n",
    "            \n",
    "    pd.DataFrame.from_dict(flow_counts).to_csv(join(root,'retained_attacks','{}.csv'.format(sr)),index=False)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
